#!/usr/bin/env python3
#
# This generates a static configuration for Prometheus
#
# Copyright Â© 2020-2021 The Software Heritage Developers.
# This file is released under the Apache-2.0 License.
#

import copy
import datetime
import os
import stat
import sys
from collections import defaultdict
from dataclasses import asdict, dataclass, fields, is_dataclass
from typing import Any, Dict, Iterable, List, Optional, Tuple

import yaml
from typing_extensions import Literal


@dataclass(frozen=True)
class RelabelConfig:
    source_labels: Optional[Tuple[str]]
    separator: Optional[str]
    target_label: Optional[str]
    regex: Optional[str]
    modulus: Optional[int]
    replacement: Optional[str]
    action: Literal[
        "replace", "keep", "drop", "hashmod", "labelmap", "labeldrop", "labelkeep"
    ]

    @classmethod
    def from_dict(cls, dict):
        init_vars = {field.name: dict.get(field.name) for field in fields(cls)}

        if init_vars.get("source_labels"):
            init_vars["source_labels"] = tuple(init_vars["source_labels"])

        return cls(**init_vars)


@dataclass(frozen=True)
class JobGroup:
    """Job parameters from which to group prometheus jobs"""

    job_name: str
    scrape_interval: Optional[int]
    scrape_timeout: Optional[int]
    metrics_path: Optional[str]
    scheme: Optional[str]
    params: Optional[Tuple[Tuple[str, Tuple[str]], ...]]
    metric_relabel_configs: Optional[Tuple[RelabelConfig]]

    @classmethod
    def from_dict(cls, dict):
        init_vars = {field.name: dict.get(field.name) for field in fields(cls)}

        if init_vars.get("metrics_path") == "/metrics":
            init_vars["metrics_path"] = None

        if init_vars.get("scheme") == "http":
            init_vars["scheme"] = None

        if init_vars.get("metric_relabel_configs"):
            init_vars["metric_relabel_configs"] = tuple(
                RelabelConfig.from_dict(args)
                for args in init_vars.get("metric_relabel_configs")
            )

        return cls(**init_vars)


def load_yaml_from_dir(dirname: str) -> Iterable[Dict[str, Any]]:
    """Load all yaml files from a given directory"""
    for filename in os.listdir(dirname):
        if not filename.endswith((".yml", ".yaml")):
            continue

        path = os.path.join(dirname, filename)
        with open(path, "r") as f:
            yield from yaml.safe_load(f)


def convert_to_dict(v: Any, field_name: Optional[str] = None) -> Any:
    if field_name == "params":
        return {kk: list(vv) for kk, vv in v}
    elif is_dataclass(v):
        return {
            field.name: convert_to_dict(getattr(v, field.name), field.name)
            for field in fields(v)
            if getattr(v, field.name) is not None
        }
    elif isinstance(v, (list, tuple)):
        return [convert_to_dict(vv) for vv in v]
    else:
        return v


def generate_scrape_configs(configs: Dict[JobGroup, List[Dict[str, Any]]]):
    """Generate a scrape_configs entry from a dict"""
    seen_jobs = set()
    for params, targets in configs.items():
        ret: Dict[str, Any] = {
            **convert_to_dict(params),
            "static_configs": targets,
        }

        ctr = 0
        orig_job_name = ret["job_name"]
        while ret["job_name"] in seen_jobs:
            ctr += 1
            ret["job_name"] = f"{orig_job_name}-{ctr}"
            for target in ret["static_configs"]:
                target.setdefault("labels", {})["job"] = orig_job_name

        seen_jobs.add(ret["job_name"])
        yield ret


def merge_prometheus_config(
    base_config: Dict[str, Any], scrape_configs: Iterable[Dict[str, Any]]
) -> Dict[str, Any]:
    """Merge the main prometheus config with scrape configs"""
    config = copy.deepcopy(base_config)
    config.setdefault("scrape_configs", []).extend(scrape_configs)
    return config


def replace_file(old_file, new_file):
    """Replace old_file with new_file, ensuring permissions are the same"""

    try:
        info = os.stat(old_file)
        os.chown(new_file, info.st_uid, info.st_gid)
        os.chmod(new_file, stat.S_IMODE(info.st_mode))
    except FileNotFoundError:
        pass

    os.rename(new_file, old_file)


if __name__ == "__main__":
    base_conffile = sys.argv[1]
    exported_dir = sys.argv[2]
    output = sys.argv[3]
    config_groups: Dict[JobGroup, List[Dict[str, Any]]] = defaultdict(list)

    for conf in load_yaml_from_dir(exported_dir):
        if "job" in conf:
            conf["job_name"] = conf.pop("job")
        if "params" in conf:
            params = conf.pop("params")
            if params is not None:
                # Hack to allow the dict serialization (used in the config_groups dict key later)
                conf["params"] = tuple((k, tuple(v)) for k, v in params.items())

        group = JobGroup.from_dict(conf)
        for key in asdict(group):
            conf.pop(key, None)
        config_groups[group].append(conf)

    with open(base_conffile, "r") as f:
        base_config = yaml.safe_load(f)

    full_config = merge_prometheus_config(
        base_config,
        generate_scrape_configs(config_groups),
    )

    now = datetime.datetime.now(tz=datetime.timezone.utc).isoformat()
    with open(output + ".tmp", "w") as f:
        print(f"# This file was generated by {sys.argv[0]} on {now}.", file=f)
        print("# Changes will be lost", file=f)
        print("", file=f)
        yaml.safe_dump(full_config, f, default_flow_style=False)

    replace_file(output, output + ".tmp")
